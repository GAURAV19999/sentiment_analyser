{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6eaa7c16-cc2c-4ad5-b713-761748dbb746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1921bb6-3d60-4dc2-ae51-4e8f7a8931f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/small_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d08217a6-0f89-4544-b873-5bde1e3c9466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ratings</th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122468</td>\n",
       "      <td>1</td>\n",
       "      <td>Recently UBISOFT had to settle a huge class-ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>495370</td>\n",
       "      <td>1</td>\n",
       "      <td>code didn't work, got me a refund.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214717</td>\n",
       "      <td>1</td>\n",
       "      <td>these do not work at all, all i get is static ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>231734</td>\n",
       "      <td>1</td>\n",
       "      <td>well let me start by saying that when i first ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>154709</td>\n",
       "      <td>1</td>\n",
       "      <td>Dont waste your money, you will just end up us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ratings                                            reviews\n",
       "0      122468        1  Recently UBISOFT had to settle a huge class-ac...\n",
       "1      495370        1                 code didn't work, got me a refund.\n",
       "2      214717        1  these do not work at all, all i get is static ...\n",
       "3      231734        1  well let me start by saying that when i first ...\n",
       "4      154709        1  Dont waste your money, you will just end up us..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a48b029-30fd-4de4-bc27-c6df7b012df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = [\"reviews\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88918e46-b1ac-4afa-807f-98a08848c66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(df.reviews.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d19a4b7-084c-4f8e-9977-38f2f0d5f3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True)\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d969dab6-97d5-421e-83e6-9848df561943",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(sentences, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c813a34e-e5da-45e1-aeca-593f688e35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['labels'] = inputs.input_ids.detach().clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a078123-71e1-4f11-bb8f-60604d159181",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand = torch.rand(inputs.input_ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c1fa935-df6e-4a7e-97e4-8a6a79079b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "003ace60-8db0-4339-b793-5ae68b60a1fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-d8b90b293d85>:5: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:983.)\n",
      "  torch.flatten(mask_arr[i].nonzero()).tolist()\n"
     ]
    }
   ],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a854d88c-c0b0-42a2-ac44-5f0c1771ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da837805-1ad2-4b5e-b0a3-9f650f7d4751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ebe6d0-960e-4dc4-acae-bd5d275f0bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset,random_split\n",
    "dataset = TensorDataset(inputs.input_ids,inputs.attention_mask,inputs.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1d13865-4450-4b01-9e8a-525cc17701e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23205797-ba0d-48af-8710-c953d21eed53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a5aed0a-8869-4728-b693-1f610af09456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 16\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "# We'll take training samples in random order. \n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  # The training samples.\n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size # Trains with this batch size.\n",
    "        )\n",
    "\n",
    "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, # The validation samples.\n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size # Evaluate with this batch size.\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92afb3b3-e732-4250-9bbc-3699e71be63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, BertConfig\n",
    "\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 1e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bf5ee6b-c3e5-40e7-800b-310736df6dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 4\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d54e7e60-011b-4731-ab0a-dc5375f9f3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59dc904a-3b20-4d9f-8e66-4f9a36db16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "686b1df4-a598-4837-a3b2-15f205ce213f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-96e4e209f30a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m        \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m        \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m        \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    " for input_ids,mask,labels in train_dataloader:\n",
    "        input_ids,mask,labels = input_ids.to(device), mask.to(device),labels.to(device)\n",
    "        out = model(input_ids, token_type_ids=None, attention_mask=mask, labels=labels,return_dict=True)\n",
    "        print(out)\n",
    "        break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa954f09-8022-419e-9289-28827a803f5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-1b5fa02c5e7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d62ea941-65e8-48f8-827d-68f436f47962",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def fit(epochs,model,train_dl,valid_dl,opt):\n",
    "    mb = master_bar(range(epochs))\n",
    "    mb.write(['epoch','train_loss','valid_loss','trn_acc','val_acc'],table=True)\n",
    "\n",
    "    for i in mb:    \n",
    "        trn_loss,val_loss = 0.0,0.0\n",
    "        trn_acc,val_acc = 0,0\n",
    "        trn_n,val_n = len(train_dl.dataset),len(valid_dl.dataset)\n",
    "        model.train()\n",
    "        for input_ids,mask,labels in progress_bar(train_dl,parent=mb):\n",
    "            input_ids,mask,labels = input_ids.to(device), mask.to(device),labels.to(device)\n",
    "            out = model(input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=mask, \n",
    "                       labels=labels,\n",
    "                       return_dict=True)\n",
    "            opt.zero_grad()\n",
    "            loss = out[0]\n",
    "            trn_loss += loss.item()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "        trn_loss /= mb.child.total\n",
    "        trn_acc /= trn_n\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for input_ids,mask,labels in progress_bar(valid_dl,parent=mb):\n",
    "                input_ids,mask,labels = input_ids.to(device), mask.to(device),labels.to(device)\n",
    "                result = model(input_ids, \n",
    "                           token_type_ids=None, \n",
    "                           attention_mask=mask,\n",
    "                           labels=labels,\n",
    "                           return_dict=True)\n",
    "                loss = result.loss\n",
    "                logits = result.logits\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= mb.child.total\n",
    "        val_acc /= val_n\n",
    "\n",
    "        mb.write([i,f'{trn_loss:.6f}',f'{val_loss:.6f}',f'{trn_acc:.6f}',f'{val_acc:.6f}'],table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e67612-c0ec-49c2-945b-dc0cc5ab4532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='1' class='' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      50.00% [1/2 02:44<02:44]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>trn_acc</th>\n",
       "      <th>val_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.552376</td>\n",
       "      <td>0.112873</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='243' class='' max='254' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      95.67% [243/254 02:32<00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit(2,model=model,train_dl=train_dataloader,valid_dl=validation_dataloader,opt=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1db820d-aebe-444c-90a7-d0d78db8350d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_size(size):\n",
    "\t\"\"\"Pretty prints a torch.Size object\"\"\"\n",
    "\tassert(isinstance(size, torch.Size))\n",
    "\treturn \" × \".join(map(str, size))\n",
    "\n",
    "def dump_tensors(gpu_only=True):\n",
    "\t\"\"\"Prints a list of the Tensors being tracked by the garbage collector.\"\"\"\n",
    "\timport gc\n",
    "\ttotal_size = 0\n",
    "\tfor obj in gc.get_objects():\n",
    "\t\ttry:\n",
    "\t\t\tif torch.is_tensor(obj):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s:%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t  \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  \" pinned\" if obj.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t  pretty_size(obj.size())))\n",
    "\t\t\t\t\ttotal_size += obj.numel()\n",
    "\t\t\telif hasattr(obj, \"data\") and torch.is_tensor(obj.data):\n",
    "\t\t\t\tif not gpu_only or obj.is_cuda:\n",
    "\t\t\t\t\tprint(\"%s → %s:%s%s%s%s %s\" % (type(obj).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   type(obj.data).__name__, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" GPU\" if obj.is_cuda else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" pinned\" if obj.data.is_pinned else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" grad\" if obj.requires_grad else \"\", \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   \" volatile\" if obj.volatile else \"\",\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t   pretty_size(obj.data.size())))\n",
    "\t\t\t\t\ttotal_size += obj.data.numel()\n",
    "\t\texcept Exception as e:\n",
    "\t\t\tpass        \n",
    "\tprint(\"Total size:\", total_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ff52036-02a2-46a6-bdc5-1012f21b36c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:144: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead\n",
      "  warnings.warn(\"torch.distributed.reduce_op is deprecated, please use \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: GPU pinned 30522 × 768\n",
      "Parameter: GPU pinned 512 × 768\n",
      "Parameter: GPU pinned 2 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 30522\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 3072 × 768\n",
      "Parameter: GPU pinned 3072\n",
      "Parameter: GPU pinned 768 × 3072\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768 × 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Parameter: GPU pinned 768\n",
      "Tensor: GPU pinned 16 × 512 × 30522\n",
      "Tensor: GPU pinned \n",
      "Total size: 359550523\n"
     ]
    }
   ],
   "source": [
    "dump_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dac2ac5-28ba-426a-b41d-018aa3dbce9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
