{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5420850-7a39-4854-bfe3-2cc8da2b8cb1",
   "metadata": {},
   "source": [
    "# About the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7f51d-e8e2-444a-a139-272c73cb3aea",
   "metadata": {},
   "source": [
    "Sentiment analysis plays a significant role in marketing. This automation can help in analyzing millions of reviews in the market. In this project, I am picking fictional video game review data from the manning live project. \n",
    "\n",
    "This project's primary goal is to understand NLP using deep learning and a complete lifecycle of developing applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a43b0d-5caa-4ee1-8b53-9ea6eec298ad",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e551351-105b-4c9b-86a9-dec9c1db4aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-26 11:43:55--  http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz\n",
      "Resolving deepyeti.ucsd.edu (deepyeti.ucsd.edu)... 169.228.63.50\n",
      "Connecting to deepyeti.ucsd.edu (deepyeti.ucsd.edu)|169.228.63.50|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 154050105 (147M) [application/octet-stream]\n",
      "Saving to: ‘Video_Games_5.json.gz’\n",
      "\n",
      "Video_Games_5.json. 100%[===================>] 146.91M  10.9MB/s    in 15s     \n",
      "\n",
      "2021-05-26 11:44:11 (9.51 MB/s) - ‘Video_Games_5.json.gz’ saved [154050105/154050105]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget http://deepyeti.ucsd.edu/jianmo/amazon/categoryFilesSmall/Video_Games_5.json.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4032d999-60f8-4520-94b8-749c10f58ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv Video_Games_5.json.gz data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718881ea-928e-4d57-b7c1-c104a73342e4",
   "metadata": {},
   "source": [
    "Downloaded data is moved into the Data folder.  Video_Games_5.json.gz  is gzipped file, and we can open the file using gunzip command in Linux. I found this helpful link https://tecadmin.net/extract-gz-file-in-linux-command/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d70448bb-acf2-45a3-95e4-7d763e06e022",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gunzip data/Video_Games_5.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8761c098-c6d2-48fc-9d5c-53fc97b71cfb",
   "metadata": {},
   "source": [
    "# Data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad45d2a-5a03-4adc-8105-6b84c079713e",
   "metadata": {},
   "source": [
    "Now that we have downloaded the dataset, we can move to analyze the data with the help of Pandas.  The downloaded dataset is a json file, and read_json can be used to read the json into the pandas data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a7b7be8-0cfa-4dd5-9d88-e89444cef17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6cc788-2c38-473d-9138-87c0a6db3621",
   "metadata": {},
   "source": [
    "Since the data is not a standard JSON, it's using Ndjson [http://ndjson.org/], which is a Newline delimited JSON data. Pandas come with an API to parse such a JSON format too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c822a072-e313-4733-bb03-af112150778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data/Video_Games_5.json',lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08379fc5-aedb-4b29-b3ce-81df99cfe64a",
   "metadata": {},
   "source": [
    "> lines=True allow this format to be possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d2036ac-e5e0-4199-9052-218983415e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>vote</th>\n",
       "      <th>style</th>\n",
       "      <th>image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>10 17, 2015</td>\n",
       "      <td>A1HP7NVNPFMA4N</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Ambrosia075</td>\n",
       "      <td>This game is a bit hard to get the hang of, bu...</td>\n",
       "      <td>but when you do it's great.</td>\n",
       "      <td>1445040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>07 27, 2015</td>\n",
       "      <td>A1JGAP0185YJI6</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>travis</td>\n",
       "      <td>I played it a while but it was alright. The st...</td>\n",
       "      <td>But in spite of that it was fun, I liked it</td>\n",
       "      <td>1437955200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>02 23, 2015</td>\n",
       "      <td>A1YJWEXHQBWK2B</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Vincent G. Mezera</td>\n",
       "      <td>ok game.</td>\n",
       "      <td>Three Stars</td>\n",
       "      <td>1424649600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>02 20, 2015</td>\n",
       "      <td>A2204E1TH211HT</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>Grandma KR</td>\n",
       "      <td>found the game a bit too complicated, not what...</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>1424390400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>12 25, 2014</td>\n",
       "      <td>A2RF5B5H74JLPE</td>\n",
       "      <td>0700026657</td>\n",
       "      <td>jon</td>\n",
       "      <td>great game, I love it and have played it since...</td>\n",
       "      <td>love this game</td>\n",
       "      <td>1419465600</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall  verified   reviewTime      reviewerID        asin  \\\n",
       "0        5      True  10 17, 2015  A1HP7NVNPFMA4N  0700026657   \n",
       "1        4     False  07 27, 2015  A1JGAP0185YJI6  0700026657   \n",
       "2        3      True  02 23, 2015  A1YJWEXHQBWK2B  0700026657   \n",
       "3        2      True  02 20, 2015  A2204E1TH211HT  0700026657   \n",
       "4        5      True  12 25, 2014  A2RF5B5H74JLPE  0700026657   \n",
       "\n",
       "        reviewerName                                         reviewText  \\\n",
       "0        Ambrosia075  This game is a bit hard to get the hang of, bu...   \n",
       "1             travis  I played it a while but it was alright. The st...   \n",
       "2  Vincent G. Mezera                                           ok game.   \n",
       "3         Grandma KR  found the game a bit too complicated, not what...   \n",
       "4                jon  great game, I love it and have played it since...   \n",
       "\n",
       "                                       summary  unixReviewTime vote style  \\\n",
       "0                  but when you do it's great.      1445040000  NaN   NaN   \n",
       "1  But in spite of that it was fun, I liked it      1437955200  NaN   NaN   \n",
       "2                                  Three Stars      1424649600  NaN   NaN   \n",
       "3                                    Two Stars      1424390400  NaN   NaN   \n",
       "4                               love this game      1419465600  NaN   NaN   \n",
       "\n",
       "  image  \n",
       "0   NaN  \n",
       "1   NaN  \n",
       "2   NaN  \n",
       "3   NaN  \n",
       "4   NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35083b4b-40c7-459e-b10c-7cae3c951e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "497577"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18bd0f8-b8b2-483b-be82-c45d1ed54bff",
   "metadata": {},
   "source": [
    "## Rating and Review Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f731a00-36ac-42b4-b5fc-46320a7f3a8f",
   "metadata": {},
   "source": [
    "We will be working on a supervised learning technique. So we need the text review written, and the rating given by the individual is the most essential feature. I have predicted the most essential field quickly, but that may not be the case generally. So with a pinch of salt, we can move on to the next step. \n",
    "\n",
    "The next step in the process is to identify the \n",
    "- Length of Dataset \n",
    "- Find the balance of the samples.\n",
    "- Create a small dataset for training\n",
    "- Hold of Large corpus for deep learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfb8fc2-09a9-4a13-aaf7-611c88e2aa46",
   "metadata": {},
   "source": [
    " ## Find the Balance of the Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8b774-fe84-46f9-8721-7ef3dfc86232",
   "metadata": {},
   "source": [
    "Based on ratings, we need the provide an equal amount of the data to model for training. For example, If we provide a more positive or negative model will be biased to the data provided. To achieve the generalization, it's crucial to balance the data, and to start with, let's check how the data is distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd02a6c9-d400-42ad-9a30-c8319884843c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    299759\n",
       "4     93654\n",
       "3     49146\n",
       "1     30883\n",
       "2     24135\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6730705-5a6d-4adc-af6d-5c986dc5993a",
   "metadata": {},
   "source": [
    "Looking at the distribution above clearly shows the data is poised towards 5(Positive) reviews. So using the complete data will skew the model towards a positive mindset. So let us create a couple of training subsets. \n",
    "  - Small corpus - This is useful for a general training\n",
    "  - large corpus - Again, we have a 497577 list of data. So It's better to reduce the number to 100K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41365f46-e086-44f3-956b-565348b14f28",
   "metadata": {},
   "source": [
    "# Small Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb559e15-e8f1-4aeb-af5e-5b38fda07e52",
   "metadata": {},
   "source": [
    "On the small corpus, we can start with 1% of the data.To make a balanced dataset out of the large dataset, I pick a percentage from each category.\n",
    "This allows me to represent the dataset in an ideal way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf682836-a8b8-491f-a36b-cbc8e39c69d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsetrecord = {1:1500,2:500,3:500,4:500,5:1500}\n",
    "\n",
    "def create_small_corpus(partion,df):\n",
    "    values = []\n",
    "    for i in partion:\n",
    "        values.append(df[df.overall==i].sample(n=partion[i],random_state=42))\n",
    "    return pd.concat(values)\n",
    "subset=create_small_corpus(subsetrecord,df)\n",
    "subset=subset[['overall','reviewText']]\n",
    "subset.rename(columns={\"overall\":\"ratings\",\"reviewText\":\"reviews\"},inplace=True)\n",
    "subset.to_csv('data/small_corpus.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd459ef4-40e2-48cc-9342-d0a1c453cbbe",
   "metadata": {},
   "source": [
    "One more prominent use of small corpus is to train faster, allowing you to experiment with multiple models before choosing one. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e29f5-4c0b-4f44-b63f-e378a7bd9f8d",
   "metadata": {},
   "source": [
    "# Large Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ed4db-cc04-4c8e-97fd-116c452e87f6",
   "metadata": {},
   "source": [
    "Take a random sample of the reviews by selecting 100,000 reviews. This way, you get a bigger representative corpus for deep learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f198694-f9c2-4c65-bc1d-2a4f1eea4d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "biggercorups = df.sample(n=100000,random_state=42)\n",
    "biggercorups=biggercorups[['overall','reviewText']]\n",
    "biggercorups.rename(columns={\"overall\":\"ratings\",\"reviewText\":\"reviews\"},inplace=True)\n",
    "biggercorups.to_csv('data/big_corpus.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a217597c-b457-4d1b-bf98-63c3fef7ecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
